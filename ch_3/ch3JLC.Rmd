---
title: "Ch. 3 workbook - jcouture"
output: html_notebook
---

```{r setup,echo=F,message=FALSE,warning=FALSE}
library(tidyverse)
```


# Probability and probability models

### The Binomial Distributuion

**Pseudocode 3.1:** Ecological sampling for pests

$$p(k,N)=\frac{N!}{k!(N-k)!}(p^{k}(1-p)^{N-k}$$
$$=\left[\frac{N-k+1}{k}\right]\left[\frac{p}{1-p}\right]p(k-1,N)$$

```{r pests0.1}
 
p=0.1 #0.2, 0.3
N=10

kVec=1:N

binom<-function(p,N=10){
  pkN<-vector(length = length(kVec))
  p0N=(1-p)^N
  
  for(i in 1:length(kVec)){
  pkN[i]<-((N-kVec[i]+1)/kVec[i])*(p/(1-p))*ifelse(pkN<2,p0N,pkN[i-1])
  }
  
  pkN0<-c(p0N,pkN)
  print(pkN0)
  
  plot(c(0,kVec),pkN0,main = paste("p = ",p,"N = 10"),xlab="k",ylab="p(k,N)")
}

binom0.1<-binom(0.1)

#binom0.1

```

```{r pests0.2}

binom0.2<-binom(0.2)

#binom0.2

```


```{r pests0.3}

binom0.3<-binom(0.3)
#binom0.3

```

** this uses the iterative method, but you can also use the below equation to "vectorize" (apply to a whole vector at once, using mutate for example)

$$p(k, N) = \binom{N}{k} p^k (1 - p)^{N - k}$$


### The Multinomial Distributuion

**Pseudocode 3.1:** Ecological sampling for pests

$$p(k_{1},k_{2},N)=\frac{N!}{k_{1}!k_{2}!}(p_{1}^{k_{1}}p_{2}^k_{2})$$

```{r pests-multi}

multinom<-function(p,N=10){
  pkN<-vector(length = length(kVec))
  p0N=(1-p)^N
  
  for(i in 1:length(kVec)){
  pkN[i]<-((N-kVec[i]+1)/kVec[i])*(p/(1-p))*ifelse(pkN<2,p0N,pkN[i-1])
  }
  
  pkN0<-c(p0N,pkN)
  print(pkN0)
}

```

###### Run as above for each $k_{n}$ separately?

### The Poisson Distributuion

*"The binomial distribution is one for which the random variable takes discrete values in desrete eperiments of trials. In the same way, the Poisson distribution (or Poisson process to indicate that something is happening over time) is one for which the random variable takes discrete values during __continuous__ sampling*

**Pseudocode 3.2:** Ecological sampling for pests

$$p(k,t)=\frac{e^{-rt}(rt)^{k}}{k!}=\left(\frac{rt}{k}\right)p(k-1,t)$$

```{r poisson}
  
poiss<-function(r,t,cut,kMax){
  kvP<-c(seq(1,kMax,by=1))
  
  p0t<-exp(-r*t)
  sum=p0t
  
  pkt<-vector(length = length(kvP))
  
  for(i in 1:length(kvP)){
    pkt[i]<-(r*t/kvP[i])*ifelse(i<2,p0t,pkt[i-1])
    sum<-sum+pkt[i]
    
    if (sum>=cut) break # while(sum<cut) <- keep doing this until this is no longer true
  }
  
  pVec<-c(p0t,pkt)
  #return(pVec)
  
  pDPlot<-plot(c(0,kvP),pVec,main = paste("Poisson\nr = ",r,", t =",t),xlab="k",ylab="sum(p(k,t))")
  #print(pkt)
  return(pDPlot)
}

  poiss(0.05,300,1,100)


```

### Poisson (non-iterative)

Set $p(0,t)$ and new opbject $sum=p(0,t)$ using:
$$p(0,t)=e^{-rt}$$


$$p(k,t)=\frac{e^{-rt}(rt)^{k}}{k!}$$
```{r possNI}

poisNI<-function(r,t,cut){
  
  pk0<-exp(-r*t)
  
  df<-data.frame(k=c(0:100),
                 pkt=c(pk0,NA),
                 rVal=c())
  df2<-df %>%
    mutate()
}
```


### The Gausian (normal) Distributuion

*"The function f(x) is the familiar "bell-shaped curve," Plot it, if it is not completely familar; vary *m* and *\Sigma* to see how they affect the shape"*

```{r gaussian}
normPlt<-function(sig,m,rng){
  gaus<-data.frame(x=seq(-rng,rng,by=0.5))
  
  gaus2<-gaus %>%
    mutate(fx=(1/(sqrt(2*pi*sig))*exp((-(x-m)^2)/2*sig^2)))
  
  nplt<-plot(gaus2,main=paste("normal distribution\nsigma =",sig,"mean =",m),xlab="x",ylab="f(x)")
return(nplt)
}

np<-normPlt(0.5,0,10)

```

### The Gamma Distributuion

**Box 3.3:**

```{r gamma}
 
...?

```


### Binomial random variables

**Pseudocode 3.3:** Generate individual random varibles from a specific distribution using the binomial distribution

```{r binomRand}
 
binRand<-function(N,p){
  U<-runif(n = 1,min = 0,max = 1)
  k=0
  suMv=rep(0,N+1)
  RkVec<-seq(1,N,by=1)
  RpkN<-numeric(length=length(RkVec))
  p0N=(1-p)^N
  
   for(i in 1:length(RkVec)){
  RpkN[i]<-((N-RkVec[i]+1)/RkVec[i])*(p/(1-p))*ifelse(i<2,p0N,RpkN[i-1])
  suMv[i+1] = suMv[i]+RpkN[i]
  #print(c(RpkN[i],U))
  if(suMv[i+1]>=U) break
  
  } 

#return(suMv)


  biRPlt<-plot(x=c(0,RkVec),y=suMv,main=paste("binomial\nN =",N,"p =",p,"U=",round(U,3)),xlab="k",ylab="cumulative prob")
return(biRPlt)
}

binRand(100,0.1)
```

##### Non-iterative method:

```{r binomRand-NI}

qbinom1 <- function(N, k, p, U) {
  qbinom1_df <- data.frame(N = N,
                          k = rep(0:N, times = length(p_vec)),
                          p = rep(p_vec, each = N + 1)) %>%
    group_by(p) %>%
    mutate(pdf = choose(N, k) * p^k * (1 - p)^(N - k),
           cdf = cumsum(pdf)) %>%
    filter(cdf > U) %>%
    summarize(U = U, N = first(N), k_successes = first(k))

  return(qbinom1_df)
}

N <- 100
p_vec <- c(0.01, 0.05, 0.10, 0.2, 0.5, 0.75)

U <- runif(n = 50, min = 0, max = 1)

qbinom_df <- lapply(U, FUN = function(x) {
  qbinom1(N, k, p_vec, x)
}) %>%
  bind_rows()

ggplot(qbinom_df, aes(y = U, x = k_successes, color = p)) +
  geom_point()

```


### Monte Carlo Technique

Adding process ($W_{t}$) and observation ($V_{t}$) error to a data model. This excersize tries to demonstrate the importance of understading the different types of error. 

##### Process error
$$N_{t+1}=sN_{t}+b_{t}+W_{t}$$

##### Observational error
$$N_{obs,t}=N_{t}+V_{t}$$
```{r mcmc-noObsErr}

mcPop<-function(s,b,sigW,sigV,N0,t){
  
  dat<-data.frame(time=0:t,
                  procErr=rnorm(t+1,0,sigW),
                  obsErr=rnorm(t+1,0,sigV),
                  N=c(N0,rep(NA,t)),
                  Nobs=c(N0+sigV,rep(NA,t)))
  
  for(i in 1:t){
    dat$N[i+1]<-s*dat$N[i]+b+dat$procErr[i+1]
    
    dat$Nobs[i+1]<-dat$N[i+1]+dat$obsErr[i+1]
  }
  
  mod<-lm(dat$N[2:nrow(dat)]~dat$N[1:nrow(dat)-1])
  
plot(dat$time,dat$N, ylab="abundance",xlab="time",type="l")
lines(dat$t,dat$Nobs,type="l",col="blue")

plot(dat$N[2:nrow(dat)]~dat$N[1:nrow(dat)-1],
     main=paste("y=",round(summary(mod)$coefficients[2,1],3),"x + ",round(summary(mod)$coefficients[1,1],3),sep=''),
xlab="population at t",
ylab="population at t+1")
abline(mod)
text(x=min(dat$N)+10,y=max(dat$N-5),labels = bquote(R^2 == .(round(summary(mod)$adj.r.squared,3))))

}


mcPop(0.8,20,10,0,50,100) #obs error=0, so plots are identical

```

```{r mcmc-obsErr}
mcPop(0.8,20,10,10,50,100)
```

```{r mcmc-noProcErr}
mcPop(0.8,20,0,10,50,100)
```